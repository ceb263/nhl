{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9YTeZOTBc0ONoKc7v/Rbi",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ceb263/nhl/blob/main/xG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMLSYBy7rtF4"
      },
      "source": [
        "# Imports and input data\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import log_loss, roc_auc_score\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.models import Sequential, load_model\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option('display.max_rows', 150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftMGJRmqdkIC",
        "outputId": "a129a833-2a44-4d7a-ae48-b9b004e6e924"
      },
      "source": [
        "!unzip data_2012-2019.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data_2012-2019.zip\n",
            "  inflating: pbp_2019.pkl            \n",
            "  inflating: __MACOSX/._pbp_2019.pkl  \n",
            "  inflating: pbp_2012.pkl            \n",
            "  inflating: __MACOSX/._pbp_2012.pkl  \n",
            "  inflating: pbp_2013.pkl            \n",
            "  inflating: __MACOSX/._pbp_2013.pkl  \n",
            "  inflating: pbp_2014.pkl            \n",
            "  inflating: __MACOSX/._pbp_2014.pkl  \n",
            "  inflating: pbp_2015.pkl            \n",
            "  inflating: __MACOSX/._pbp_2015.pkl  \n",
            "  inflating: pbp_2016.pkl            \n",
            "  inflating: __MACOSX/._pbp_2016.pkl  \n",
            "  inflating: pbp_2017.pkl            \n",
            "  inflating: __MACOSX/._pbp_2017.pkl  \n",
            "  inflating: pbp_2018.pkl            \n",
            "  inflating: __MACOSX/._pbp_2018.pkl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmTRl1ZYt7B4"
      },
      "source": [
        "# read data\n",
        "plays = pd.read_pickle('pbp_2012.pkl')\n",
        "plays['Season'] = 2012\n",
        "plays2013 = pd.read_pickle('pbp_2013.pkl')\n",
        "plays2013['Season'] = 2013\n",
        "plays2014 = pd.read_pickle('pbp_2014.pkl')\n",
        "plays2014['Season'] = 2014\n",
        "plays2015 = pd.read_pickle('pbp_2015.pkl')\n",
        "plays2015['Season'] = 2015\n",
        "plays2016 = pd.read_pickle('pbp_2016.pkl')\n",
        "plays2016['Season'] = 2016\n",
        "plays2017 = pd.read_pickle('pbp_2017.pkl')\n",
        "plays2017['Season'] = 2017\n",
        "plays2018 = pd.read_pickle('pbp_2018.pkl')\n",
        "plays2018['Season'] = 2018\n",
        "plays2019 = pd.read_pickle('pbp_2019.pkl')\n",
        "plays2019['Season'] = 2019\n",
        "plays = pd.concat([plays, plays2013], ignore_index=True)\n",
        "plays = pd.concat([plays, plays2014], ignore_index=True)\n",
        "plays = pd.concat([plays, plays2015], ignore_index=True)\n",
        "plays = pd.concat([plays, plays2016], ignore_index=True)\n",
        "plays = pd.concat([plays, plays2017], ignore_index=True)\n",
        "plays = pd.concat([plays, plays2018], ignore_index=True)\n",
        "plays = pd.concat([plays, plays2019], ignore_index=True)\n",
        "\n",
        "del plays2013, plays2014, plays2015, plays2016, plays2017, plays2018, plays2019"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TXg11RbuaYP"
      },
      "source": [
        "# data preprocessing\n",
        "def preprocess_plays(df):\n",
        "    # remove null location data\n",
        "    df = df.loc[~df['xC'].isnull()]\n",
        "    df = df.loc[~df['yC'].isnull()]\n",
        "\n",
        "    # get previous event time and location\n",
        "    df = df.sort_values(by=['Game_Id','Period','Seconds_Elapsed'])\n",
        "    df['prev_Game_Id'] = df['Game_Id'].shift(1)\n",
        "    df['prev_Period'] = df['Period'].shift(1)\n",
        "    df['keepPrev'] = ((df['prev_Game_Id']==df['Game_Id']) & (df['prev_Period']==df['Period'])).astype(int)\n",
        "    df['prev_Event'] = df['Event'].shift(1)\n",
        "    df['prev_Seconds_Elapsed'] = df['Seconds_Elapsed'].shift(1)\n",
        "    df['prev_xC'] = df['xC'].shift(1)\n",
        "    df['prev_yC'] = df['yC'].shift(1)\n",
        "    df.at[df['keepPrev']==0, ['prev_Event','prev_Seconds_Elapsed','prev_xC','prev_yC']] = np.NaN\n",
        "    df = df.loc[~df['prev_Event'].isnull()]\n",
        "\n",
        "    # get time elapsed, and distance from previous event\n",
        "    df['timeSincePrev'] = df['Seconds_Elapsed'] - df['prev_Seconds_Elapsed']\n",
        "    df['distanceSincePrev'] = np.sqrt(np.square(df['xC']-df['prev_xC']) + np.square(df['yC']-df['prev_yC']))\n",
        "    df['yDistanceSincePrev'] = np.abs(df['yC'] - df['prev_yC'])\n",
        "\n",
        "    # remove invalid data\n",
        "    df = df.loc[(df['timeSincePrev']>0) | (df['timeSincePrev'].isnull())]\n",
        "\n",
        "    # filter for only shots and shot attempts\n",
        "    df = df.loc[df['Event'].isin(['BLOCK','MISS','SHOT','GOAL'])]\n",
        "\n",
        "    # filter for only most common game states\n",
        "    df = df.loc[df['Strength'].isin(['5x5','4x5','3x5','5x4','4x4','5x3','4x3','6x5','5x6','3x4','3x3'])]\n",
        "\n",
        "    # get previous shot time and location, and then calculate derived metrics\n",
        "    df['prevShot_Game_Id'] = df['Game_Id'].shift(1)\n",
        "    df['prevShot_Period'] = df['Period'].shift(1)\n",
        "    df['keepPrevShot'] = ((df['prevShot_Game_Id']==df['Game_Id']) & (df['prevShot_Period']==df['Period'])).astype(int)\n",
        "    df['prevShot_Seconds_Elapsed'] = df['Seconds_Elapsed'].shift(1)\n",
        "    df['prevShot_xC'] = df['xC'].shift(1)\n",
        "    df['prevShot_yC'] = df['yC'].shift(1)\n",
        "    df['prevShot_Ev_Team'] = df['Ev_Team'].shift(1)\n",
        "    df['prevShot_sameTeam'] = (df['prevShot_Ev_Team']==df['Ev_Team']).astype(int)\n",
        "    df.at[df['keepPrevShot']==0, ['prevShot_Seconds_Elapsed','prevShot_xC','prevShot_yC','prevShot_Ev_Team']] = np.NaN\n",
        "    df['timeSincePrevShot'] = df['Seconds_Elapsed'] - df['prevShot_Seconds_Elapsed']\n",
        "    df['distanceSincePrevShot'] = np.sqrt(np.square(df['xC']-df['prevShot_xC']) + np.square(df['yC']-df['prevShot_yC']))\n",
        "    df['yDistanceSincePrevShot'] = np.abs(df['yC'] - df['prevShot_yC'])\n",
        "\n",
        "    # adjust shot locations so everything is on the same side of the ice\n",
        "    # TODO this isn't quite right - shots from the D zone (into an empty net, for example), will not be adjusted correctly\n",
        "    df['loc_adjust_factor'] = (((df['xC']>0).astype(int).astype(float)) - 0.5) * 2\n",
        "    df['x_adj'] = df['xC']*df['loc_adjust_factor']\n",
        "    df['y_adj'] = df['yC']*df['loc_adjust_factor']\n",
        "    df['prev_loc_adjust_factor'] = (((df['prev_xC']>0).astype(int).astype(float)) - 0.5) * 2\n",
        "    df['prev_x_adj'] = df['prev_xC']*df['prev_loc_adjust_factor']\n",
        "    df['prev_y_adj'] = df['prev_yC']*df['prev_loc_adjust_factor']\n",
        "    df['prevShot_loc_adjust_factor'] = (((df['prevShot_xC']>0).astype(int).astype(float)) - 0.5) * 2\n",
        "    df['prevShot_x_adj'] = df['prevShot_xC']*df['prevShot_loc_adjust_factor']\n",
        "    df['prevShot_y_adj'] = df['prevShot_yC']*df['prevShot_loc_adjust_factor']\n",
        "\n",
        "    # fill nulls\n",
        "    df[['prevShot_Seconds_Elapsed','prevShot_yC','prevShot_y_adj','prevShot_xC']] = \\\n",
        "        df[['prevShot_Seconds_Elapsed','prevShot_yC','prevShot_y_adj','prevShot_xC']].fillna(0)\n",
        "    df[['prevShot_x_adj','distanceSincePrevShot','yDistanceSincePrevShot']] = df[['prevShot_x_adj','distanceSincePrevShot','yDistanceSincePrevShot']].fillna(-1)\n",
        "    df[['timeSincePrevShot']] = df[['timeSincePrevShot']].fillna(1200)\n",
        "\n",
        "    # fix time since prev shot if prev shot was in another period\n",
        "    df.at[df['timeSincePrevShot']<0, 'timeSincePrevShot'] = 1200\n",
        "\n",
        "    # adjust score to be score for and against, instead of home and away\n",
        "    df['homeTeamShot'] = (df['Home_Team']==df['Ev_Team']).astype(int)\n",
        "    df['scoreFor'] = (df['Home_Score']*df['homeTeamShot']) + (df['Away_Score']*(1-df['homeTeamShot']))\n",
        "    df['scoreAgainst'] = (df['Away_Score']*df['homeTeamShot']) + (df['Home_Score']*(1-df['homeTeamShot']))\n",
        "    df['scoreDiff'] = df['scoreFor'] - df['scoreAgainst']\n",
        "\n",
        "    # add target variable\n",
        "    df['goal'] = (df['Event']=='GOAL').astype(int)\n",
        "\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LlKy5vD-IFv"
      },
      "source": [
        "shots = preprocess_plays(plays)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WvRQZoB6uTLm",
        "outputId": "6f789c34-a5d6-48c6-b527-a69a716bc40e"
      },
      "source": [
        "# select feature and target columns\n",
        "X = shots[['Period','Seconds_Elapsed','scoreFor','scoreAgainst','scoreDiff','xC','yC','prev_Seconds_Elapsed','prev_xC','prev_yC','timeSincePrev','distanceSincePrev',\n",
        "           'yDistanceSincePrev','prevShot_Seconds_Elapsed','prevShot_xC','prevShot_yC','prevShot_sameTeam','timeSincePrevShot','distanceSincePrevShot',\n",
        "           'yDistanceSincePrevShot','x_adj','y_adj','prev_x_adj','prev_y_adj','prevShot_x_adj','prevShot_y_adj','Strength','Ev_Zone','Type','prev_Event','goal','Season']]\n",
        "y = shots[['goal','Season']]\n",
        "\n",
        "# train/test split\n",
        "#[X_train, X_test, y_train, y_test] = train_test_split(X, y, test_size=0.3, random_state=26)\n",
        "X_train = X.loc[X['Season']!=2019]\n",
        "X_test = X.loc[X['Season']==2019]\n",
        "y_train = y.loc[y['Season']!=2019]['goal'].values\n",
        "y_test = y.loc[y['Season']==2019]['goal'].values\n",
        "\n",
        "# categorical feature encodings\n",
        "mean_codes_strength = X_train.groupby(['Strength'])['goal'].mean().to_dict()\n",
        "mean_codes_zone = X_train.groupby(['Ev_Zone'])['goal'].mean().to_dict()\n",
        "mean_codes_type = X_train.groupby(['Type'])['goal'].mean().to_dict()\n",
        "mean_codes_prevEvent = X_train.groupby(['prev_Event'])['goal'].mean().to_dict()\n",
        "\n",
        "tot_count = X_train['goal'].count()\n",
        "count_codes_strength = (X_train.groupby(['Strength'])['goal'].count()/tot_count).to_dict()\n",
        "count_codes_zone = (X_train.groupby(['Ev_Zone'])['goal'].count()/tot_count).to_dict()\n",
        "count_codes_type = (X_train.groupby(['Type'])['goal'].count()/tot_count).to_dict()\n",
        "count_codes_prevEvent = (X_train.groupby(['prev_Event'])['goal'].count()/tot_count).to_dict()\n",
        "\n",
        "X_train['Strength_meanEnc'] = X_train['Strength'].map(mean_codes_strength)\n",
        "X_test['Strength_meanEnc'] = X_test['Strength'].map(mean_codes_strength)\n",
        "X_train['Ev_Zone_meanEnc'] = X_train['Ev_Zone'].map(mean_codes_zone)\n",
        "X_test['Ev_Zone_meanEnc'] = X_test['Ev_Zone'].map(mean_codes_zone)\n",
        "X_train['Type_meanEnc'] = X_train['Type'].map(mean_codes_type)\n",
        "X_test['Type_meanEnc'] = X_test['Type'].map(mean_codes_type)\n",
        "X_train['prev_Event_meanEnc'] = X_train['prev_Event'].map(mean_codes_prevEvent)\n",
        "X_test['prev_Event_meanEnc'] = X_test['prev_Event'].map(mean_codes_prevEvent)\n",
        "X_train['Strength_countEnc'] = X_train['Strength'].map(count_codes_strength)\n",
        "X_test['Strength_countEnc'] = X_test['Strength'].map(count_codes_strength)\n",
        "X_train['Ev_Zone_countEnc'] = X_train['Ev_Zone'].map(count_codes_zone)\n",
        "X_test['Ev_Zone_countEnc'] = X_test['Ev_Zone'].map(count_codes_zone)\n",
        "X_train['Type_countEnc'] = X_train['Type'].map(count_codes_type)\n",
        "X_test['Type_countEnc'] = X_test['Type'].map(count_codes_type)\n",
        "X_train['prev_Event_countEnc'] = X_train['prev_Event'].map(count_codes_prevEvent)\n",
        "X_test['prev_Event_countEnc'] = X_test['prev_Event'].map(count_codes_prevEvent)\n",
        "\n",
        "X_train_df = X_train.copy(deep=True)\n",
        "X_test_df = X_test.copy(deep=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7Ox0zc47Jpy"
      },
      "source": [
        "features = ['Period','Seconds_Elapsed','scoreDiff','yC','prev_Seconds_Elapsed','timeSincePrev','distanceSincePrev',\n",
        "           'prevShot_Seconds_Elapsed','prevShot_sameTeam','timeSincePrevShot',\n",
        "           'x_adj','y_adj','Strength_meanEnc','Ev_Zone_meanEnc','Type_meanEnc']\n",
        "X_train = X_train_df[features].values\n",
        "X_test = X_test_df[features].values\n",
        "\n",
        "# apply scaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLecsfqrQk9W"
      },
      "source": [
        "# Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8q4DRF0tUCf"
      },
      "source": [
        "[_, X_subsample, _, y_subsample] = train_test_split(X_train, y_train, test_size=0.05, random_state=26)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAzxlupkv_e7",
        "outputId": "3f983298-e082-4ed7-ebb6-03823f89e543"
      },
      "source": [
        "X_subsample.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41460, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "y_yuJ80xs-_G",
        "outputId": "93adb231-b960-4f2e-f274-e31bc9ab66a6"
      },
      "source": [
        "model_test = GradientBoostingClassifier()\n",
        "\n",
        "param_dist = {\n",
        "    'max_depth' : [12,15],\n",
        "    'min_samples_leaf' : [1000,5000]\n",
        "}\n",
        "\n",
        "random_search = GridSearchCV(model_test, param_dist, scoring=['neg_log_loss','roc_auc'], refit='neg_log_loss', cv=3, return_train_score=True)\n",
        "random_search.fit(X_subsample, y_subsample)\n",
        "\n",
        "report_cols = ['mean_test_neg_log_loss','mean_test_roc_auc']+['param_'+param for param in param_dist]\n",
        "report = pd.DataFrame(random_search.cv_results_)[report_cols].sort_values(by='mean_test_neg_log_loss', ascending=False)\n",
        "report"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_test_neg_log_loss</th>\n",
              "      <th>mean_test_roc_auc</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_min_samples_leaf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.159329</td>\n",
              "      <td>0.801846</td>\n",
              "      <td>12</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.159639</td>\n",
              "      <td>0.800997</td>\n",
              "      <td>15</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.161883</td>\n",
              "      <td>0.789792</td>\n",
              "      <td>12</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.161883</td>\n",
              "      <td>0.789792</td>\n",
              "      <td>15</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_test_neg_log_loss  ...  param_min_samples_leaf\n",
              "0               -0.159329  ...                    1000\n",
              "2               -0.159639  ...                    1000\n",
              "1               -0.161883  ...                    5000\n",
              "3               -0.161883  ...                    5000\n",
              "\n",
              "[4 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjskfGCRQp6a"
      },
      "source": [
        "# Selected Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgyCM8zkojwB"
      },
      "source": [
        "Originally was testing different types of models (neural nets, gradient boosting trees, random forest, K nearest neighbors, and logistic regression), with a meta model built on top. Neural networks, gradient boosting, and random forest all performed similarly, and better than KNN or logistic regression. Performance on test data did not improve from those models by themselves to adding a meta model, so the final model is just a gradient boosting classifier.\n",
        "\n",
        "The final model trained on data from the 2012 - 2018 seasons, and used the 2019 season as a test set. The model achieved a LogLoss of 0.1623 and an AUC of 0.8255 on the test data (min_samples_leaf=200, max_depth=10)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x06SDVv_PjM8"
      },
      "source": [
        "X = np.concatenate((X_train, X_test))\n",
        "y = np.concatenate((y_train, y_test))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ-wHaqtPseR"
      },
      "source": [
        "model = GradientBoostingClassifier(min_samples_leaf=200, max_depth=10)\n",
        "model.fit(X, y)\n",
        "pickle.dump(model, open('xG_gb.pkl', 'wb'))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck2v8xAJOaQF",
        "outputId": "a23a3ba0-9aa6-4d10-f046-c9620c5d4584"
      },
      "source": [
        "model_gb = GradientBoostingClassifier(min_samples_leaf=200, max_depth=10)\n",
        "model_gb.fit(X_train, y_train)\n",
        "preds_gb = model_gb.predict_proba(X_test)[:,1]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_test, preds_gb))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_test, preds_gb))))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss score: 0.16234477772192488\n",
            "AUC score: 0.8254788756324156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "iAxtOwGc55gd",
        "outputId": "2d6d93d9-91cc-4d82-af48-214e27aac884"
      },
      "source": [
        "gb_features = pd.DataFrame()\n",
        "gb_features['feature'] = features\n",
        "gb_features['importance'] = model_gb.feature_importances_\n",
        "gb_features.sort_values(by='importance', ascending=False)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>x_adj</td>\n",
              "      <td>0.219661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Ev_Zone_meanEnc</td>\n",
              "      <td>0.160604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yC</td>\n",
              "      <td>0.132226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>y_adj</td>\n",
              "      <td>0.096482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>scoreDiff</td>\n",
              "      <td>0.068501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Type_meanEnc</td>\n",
              "      <td>0.064492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Period</td>\n",
              "      <td>0.047695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>distanceSincePrev</td>\n",
              "      <td>0.043232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>timeSincePrevShot</td>\n",
              "      <td>0.034820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>prevShot_Seconds_Elapsed</td>\n",
              "      <td>0.030950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Strength_meanEnc</td>\n",
              "      <td>0.027674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>prevShot_sameTeam</td>\n",
              "      <td>0.021138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Seconds_Elapsed</td>\n",
              "      <td>0.020527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>prev_Seconds_Elapsed</td>\n",
              "      <td>0.020096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>timeSincePrev</td>\n",
              "      <td>0.011902</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     feature  importance\n",
              "10                     x_adj    0.219661\n",
              "13           Ev_Zone_meanEnc    0.160604\n",
              "3                         yC    0.132226\n",
              "11                     y_adj    0.096482\n",
              "2                  scoreDiff    0.068501\n",
              "14              Type_meanEnc    0.064492\n",
              "0                     Period    0.047695\n",
              "6          distanceSincePrev    0.043232\n",
              "9          timeSincePrevShot    0.034820\n",
              "7   prevShot_Seconds_Elapsed    0.030950\n",
              "12          Strength_meanEnc    0.027674\n",
              "8          prevShot_sameTeam    0.021138\n",
              "1            Seconds_Elapsed    0.020527\n",
              "4       prev_Seconds_Elapsed    0.020096\n",
              "5              timeSincePrev    0.011902"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6GBAnBpgk0_"
      },
      "source": [
        "pickle.dump(model_gb, open('gb.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7-AGI5NI2Ex"
      },
      "source": [
        "model_gb = pickle.load(open('gb.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9Yyuza-KYZx",
        "outputId": "27e42161-7864-4a68-bfc4-aa0cc2262e0b"
      },
      "source": [
        "preds_gb = model_gb.predict_proba(X_train)[:,1]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_train, preds_gb))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_train, preds_gb))))\n",
        "np.save('train_preds_gb.npy', preds_gb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss score: 0.1581178923761096\n",
            "AUC score: 0.8192213657832067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArSiwODDr8R0",
        "outputId": "86d20910-a851-4e6b-d3ef-1c07ba0bf854"
      },
      "source": [
        "model_gb2 = GradientBoostingClassifier(max_depth=3, min_weight_fraction_leaf=0.001)\n",
        "model_gb2.fit(X_train, y_train)\n",
        "preds_gb2 = model_gb2.predict_proba(X_test)[:,1]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_test, preds_gb2))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_test, preds_gb2))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss score: 0.1658067883554617\n",
            "AUC score: 0.8163280936824684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFcZdW3Mgf3k"
      },
      "source": [
        "pickle.dump(model_gb2, open('gb2.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EkKAX0RJExO"
      },
      "source": [
        "model_gb2 = pickle.load(open('gb2.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guwjDotEK3jj",
        "outputId": "5da14a0e-4739-4bcf-a8d5-f72d3e59d87b"
      },
      "source": [
        "preds_gb2 = model_gb2.predict_proba(X_train)[:,1]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_train, preds_gb2))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_train, preds_gb2))))\n",
        "np.save('train_preds_gb2.npy', preds_gb2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss score: 0.15827058176118222\n",
            "AUC score: 0.818599677692736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w04F7fBAox6g",
        "outputId": "87e31e92-60bc-4f5f-d0de-02582dffbab5"
      },
      "source": [
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(X_train, y_train)\n",
        "preds_lr = model_lr.predict_proba(X_test)[:,1]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_test, preds_lr))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_test, preds_lr))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss score: 0.17561467421598137\n",
            "AUC score: 0.7684700372074639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcP-fDYjbl5t"
      },
      "source": [
        "pickle.dump(model_lr, open('lr.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9XPlSz3JG3o"
      },
      "source": [
        "model_lr = pickle.load(open('lr.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3VPWrsFK_E_",
        "outputId": "4373a629-32fd-4c0e-defd-63e15e0e728b"
      },
      "source": [
        "preds_lr = model_lr.predict_proba(X_train)[:,1]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_train, preds_lr))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_train, preds_lr))))\n",
        "np.save('train_preds_lr.npy', preds_lr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss score: 0.16806671387027766\n",
            "AUC score: 0.7675220516382505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0bAgLKQu0rM",
        "outputId": "acfe65ee-1d39-4671-b5dd-8876bd7e151b"
      },
      "source": [
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_train, y_train)\n",
        "preds_rf = model_rf.predict_proba(X_test)[:,1]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_test, preds_rf))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_test, preds_rf))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss score: 0.2025529015331919\n",
            "AUC score: 0.7921210034054453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "zCuUbUPerdUz",
        "outputId": "b1b7160a-4afc-46c0-820f-a37b6443fad0"
      },
      "source": [
        "rf_features = pd.DataFrame()\n",
        "rf_features['feature'] = features\n",
        "rf_features['importance'] = model_rf.feature_importances_\n",
        "rf_features.sort_values(by='importance', ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>distanceSincePrev</td>\n",
              "      <td>0.133150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>prev_Seconds_Elapsed</td>\n",
              "      <td>0.118159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Seconds_Elapsed</td>\n",
              "      <td>0.118000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>prevShot_Seconds_Elapsed</td>\n",
              "      <td>0.117813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>x_adj</td>\n",
              "      <td>0.094005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>y_adj</td>\n",
              "      <td>0.074657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yC</td>\n",
              "      <td>0.074262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>timeSincePrevShot</td>\n",
              "      <td>0.062439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>scoreDiff</td>\n",
              "      <td>0.055062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>timeSincePrev</td>\n",
              "      <td>0.040902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Period</td>\n",
              "      <td>0.033512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Type_meanEnc</td>\n",
              "      <td>0.030014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Ev_Zone_meanEnc</td>\n",
              "      <td>0.020639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Strength_meanEnc</td>\n",
              "      <td>0.018740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>prevShot_sameTeam</td>\n",
              "      <td>0.008644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     feature  importance\n",
              "6          distanceSincePrev    0.133150\n",
              "4       prev_Seconds_Elapsed    0.118159\n",
              "1            Seconds_Elapsed    0.118000\n",
              "7   prevShot_Seconds_Elapsed    0.117813\n",
              "10                     x_adj    0.094005\n",
              "11                     y_adj    0.074657\n",
              "3                         yC    0.074262\n",
              "9          timeSincePrevShot    0.062439\n",
              "2                  scoreDiff    0.055062\n",
              "5              timeSincePrev    0.040902\n",
              "0                     Period    0.033512\n",
              "14              Type_meanEnc    0.030014\n",
              "13           Ev_Zone_meanEnc    0.020639\n",
              "12          Strength_meanEnc    0.018740\n",
              "8          prevShot_sameTeam    0.008644"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MANIV_I0bjAz"
      },
      "source": [
        "pickle.dump(model_rf, open('rf.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiF8Z_AdJIrp"
      },
      "source": [
        "model_rf = pickle.load(open('rf.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC1RJVWYLLzt",
        "outputId": "b9b31c79-bbb0-4f1f-e92d-60f55ab264f8"
      },
      "source": [
        "preds_rf = model_rf.predict_proba(X_train)[:,1]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_train, preds_rf))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_train, preds_rf))))\n",
        "np.save('train_preds_rf.npy', preds_rf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss score: 0.14290832802468434\n",
            "AUC score: 0.8902308978742874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M3STVrdprJe"
      },
      "source": [
        "def create_model_nn(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, input_dim=input_dim))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(64))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoPtyVM0qK6x",
        "outputId": "af9d9d80-1435-4b12-b68a-2e45f21e41bf"
      },
      "source": [
        "model_nn = create_model_nn(X_train.shape[1])\n",
        "model_nn.fit(X_train, y_train, verbose=1, epochs=10, batch_size=2048)\n",
        "preds_nn = model_nn.predict(X_test)[:,0]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_test, np.clip(preds_nn, a_min=10e-5, a_max = 1-10e-5)))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_test, np.clip(preds_nn, a_min=10e-5, a_max = 1-10e-5)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "405/405 [==============================] - 3s 5ms/step - loss: 0.1856\n",
            "Epoch 2/10\n",
            "405/405 [==============================] - 2s 4ms/step - loss: 0.1645\n",
            "Epoch 3/10\n",
            "405/405 [==============================] - 2s 4ms/step - loss: 0.1625\n",
            "Epoch 4/10\n",
            "405/405 [==============================] - 2s 4ms/step - loss: 0.1614\n",
            "Epoch 5/10\n",
            "405/405 [==============================] - 2s 4ms/step - loss: 0.1610\n",
            "Epoch 6/10\n",
            "405/405 [==============================] - 2s 4ms/step - loss: 0.1610\n",
            "Epoch 7/10\n",
            "405/405 [==============================] - 2s 4ms/step - loss: 0.1595\n",
            "Epoch 8/10\n",
            "405/405 [==============================] - 2s 4ms/step - loss: 0.1585\n",
            "Epoch 9/10\n",
            "405/405 [==============================] - 2s 4ms/step - loss: 0.1593\n",
            "Epoch 10/10\n",
            "405/405 [==============================] - 2s 4ms/step - loss: 0.1584\n",
            "LogLoss score: 0.1641512059568805\n",
            "AUC score: 0.8188887203127735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUKQvQP5gp6Y"
      },
      "source": [
        "model_nn.save('nn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-phcoFYJPkB"
      },
      "source": [
        "model_nn = load_model('nn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY79XYmHLTrr",
        "outputId": "b1e060fb-f787-4cd4-9dd5-4bfef8835ed9"
      },
      "source": [
        "preds_nn = model_nn.predict(X_train)[:,0]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_train, np.clip(preds_nn, a_min=10e-5, a_max = 1-10e-5)))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_train, np.clip(preds_nn, a_min=10e-5, a_max = 1-10e-5)))))\n",
        "np.save('train_preds_nn.npy', preds_nn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss score: 0.16151307566498868\n",
            "AUC score: 0.8208424245852204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOLdd0bgp844"
      },
      "source": [
        "def create_model_nn2(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(2048, input_dim=input_dim))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sanc0kIyqFzK",
        "outputId": "99885cd5-7fb2-45cc-8fcc-2bd45b9d0302"
      },
      "source": [
        "model_nn2 = create_model_nn2(X_train.shape[1])\n",
        "model_nn2.fit(X_train, y_train, verbose=1, epochs=10, batch_size=2048)\n",
        "preds_nn2 = model_nn2.predict(X_test)[:,0]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_test, np.clip(preds_nn2, a_min=10e-5, a_max = 1-10e-5)))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_test, np.clip(preds_nn2, a_min=10e-5, a_max = 1-10e-5)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "405/405 [==============================] - 5s 10ms/step - loss: 0.1820\n",
            "Epoch 2/10\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1627\n",
            "Epoch 3/10\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1621\n",
            "Epoch 4/10\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1601\n",
            "Epoch 5/10\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1585\n",
            "Epoch 6/10\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1587\n",
            "Epoch 7/10\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1591\n",
            "Epoch 8/10\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1585\n",
            "Epoch 9/10\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1586\n",
            "Epoch 10/10\n",
            "405/405 [==============================] - 4s 10ms/step - loss: 0.1580\n",
            "LogLoss score: 0.1644034389894902\n",
            "AUC score: 0.8174647173880174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PUeHh2WhhKZ"
      },
      "source": [
        "model_nn2.save('nn2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSiRXPSlJfQf"
      },
      "source": [
        "model_nn2 = load_model('nn2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vb2Qo66LrYD",
        "outputId": "9df338fb-1b19-4002-fb27-54214a9f6dc3"
      },
      "source": [
        "preds_nn2 = model_nn2.predict(X_train)[:,0]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_train, np.clip(preds_nn2, a_min=10e-5, a_max = 1-10e-5)))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_train, np.clip(preds_nn2, a_min=10e-5, a_max = 1-10e-5)))))\n",
        "np.save('train_preds_nn2.npy', preds_nn2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss score: 0.15588459537329236\n",
            "AUC score: 0.8238504049570357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBilXh0r3rOw"
      },
      "source": [
        "# Meta Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIyTcXZYRl4i"
      },
      "source": [
        "np.save('test_actuals.npy', y_test)\n",
        "np.save('train_actuals.npy', y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bK2IYLRR3SE"
      },
      "source": [
        "preds_gb = np.load('train_preds_gb.npy')\n",
        "preds_gb2 = np.load('train_preds_gb2.npy')\n",
        "preds_lr = np.load('train_preds_lr.npy')\n",
        "preds_nn = np.load('train_preds_nn.npy')\n",
        "preds_nn2 = np.load('train_preds_nn2.npy')\n",
        "preds_rf = np.load('train_preds_rf.npy')\n",
        "\n",
        "preds_gb_test = np.load('test_preds_gb.npy')\n",
        "preds_gb2_test = np.load('test_preds_gb2.npy')\n",
        "preds_lr_test = np.load('test_preds_lr.npy')\n",
        "preds_nn_test = np.load('test_preds_nn.npy')\n",
        "preds_nn2_test = np.load('test_preds_nn2.npy')\n",
        "preds_rf_test = np.load('test_preds_rf.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRlrStzk4MuW"
      },
      "source": [
        "X_meta = np.column_stack((preds_gb, preds_gb2, preds_rf, preds_lr, preds_nn, preds_nn2))\n",
        "X_meta = np.concatenate((X_train, X_meta), axis=1)\n",
        "X_meta_test = np.column_stack((preds_gb_test, preds_gb2_test, preds_rf_test, preds_lr_test, preds_nn_test, preds_nn2_test))\n",
        "X_meta_test = np.concatenate((X_test, X_meta_test), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P44BrRfWcGFV"
      },
      "source": [
        "def create_model_nn_meta(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1, input_dim=input_dim))\n",
        "    #model.add(Activation('relu'))\n",
        "    #model.add(Dropout(0.5))\n",
        "\n",
        "    #model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC7mjvsHcLxQ",
        "outputId": "93e85cbd-c166-4060-ea8a-6b6f94c8cc1e"
      },
      "source": [
        "#model_nn_meta = create_model_nn_meta(X_meta.shape[1])\n",
        "model_nn_meta.fit(X_meta, y_train, verbose=1, epochs=10, batch_size=512)\n",
        "preds_nn_meta = model_nn_meta.predict(X_meta_test)[:,0]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_test, np.clip(preds_nn_meta, a_min=10e-5, a_max = 1-10e-5)))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_test, np.clip(preds_nn_meta, a_min=10e-5, a_max = 1-10e-5)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1620/1620 [==============================] - 3s 2ms/step - loss: 0.1488\n",
            "Epoch 2/10\n",
            "1620/1620 [==============================] - 3s 2ms/step - loss: 0.1478\n",
            "Epoch 3/10\n",
            "1620/1620 [==============================] - 3s 2ms/step - loss: 0.1467\n",
            "Epoch 4/10\n",
            "1620/1620 [==============================] - 3s 2ms/step - loss: 0.1457\n",
            "Epoch 5/10\n",
            "1620/1620 [==============================] - 3s 2ms/step - loss: 0.1448\n",
            "Epoch 6/10\n",
            "1620/1620 [==============================] - 3s 2ms/step - loss: 0.1439\n",
            "Epoch 7/10\n",
            "1620/1620 [==============================] - 3s 2ms/step - loss: 0.1430\n",
            "Epoch 8/10\n",
            "1620/1620 [==============================] - 3s 2ms/step - loss: 0.1421\n",
            "Epoch 9/10\n",
            "1620/1620 [==============================] - 3s 2ms/step - loss: 0.1413\n",
            "Epoch 10/10\n",
            "1620/1620 [==============================] - 3s 2ms/step - loss: 0.1405\n",
            "LogLoss score: 0.16684700429050514\n",
            "AUC score: 0.814733401315431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "DUd9y9_-3qWN",
        "outputId": "7bcf9edd-ccf7-4672-db08-b985d835f4b7"
      },
      "source": [
        "model_test = RandomForestClassifier()\n",
        "\n",
        "param_dist = {\n",
        "    'max_depth' : [1,5,10]\n",
        "}\n",
        "\n",
        "random_search = GridSearchCV(model_test, param_dist, scoring=['neg_log_loss','roc_auc'], refit='neg_log_loss', cv=3, return_train_score=True)\n",
        "random_search.fit(X_meta, y_train)\n",
        "\n",
        "report_cols = ['mean_test_neg_log_loss','mean_test_roc_auc']+['param_'+param for param in param_dist]\n",
        "report = pd.DataFrame(random_search.cv_results_)[report_cols].sort_values(by='mean_test_neg_log_loss', ascending=False)\n",
        "report"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_test_neg_log_loss</th>\n",
              "      <th>mean_test_roc_auc</th>\n",
              "      <th>param_max_depth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.094348</td>\n",
              "      <td>0.962418</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.116484</td>\n",
              "      <td>0.940895</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.161838</td>\n",
              "      <td>0.771469</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_test_neg_log_loss  mean_test_roc_auc param_max_depth\n",
              "2               -0.094348           0.962418              10\n",
              "1               -0.116484           0.940895               5\n",
              "0               -0.161838           0.771469               1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5wMdEM8QnmW",
        "outputId": "1e9a0d55-8718-49d6-a8c8-19d30b42bc70"
      },
      "source": [
        "model_meta = RandomForestClassifier(max_depth=1)\n",
        "model_meta.fit(X_meta, y_train)\n",
        "test_preds_meta = model_meta.predict_proba(X_meta_test)[:,1]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_test, test_preds_meta))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_test, test_preds_meta))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss score: 0.17531882694905196\n",
            "AUC score: 0.7488173236352991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PTPvaxBXN-a",
        "outputId": "110506a2-9141-4473-f79a-2da95918f7de"
      },
      "source": [
        "model_meta = GradientBoostingClassifier(max_depth=1)\n",
        "model_meta.fit(X_meta, y_train)\n",
        "test_preds_meta = model_meta.predict_proba(X_meta_test)[:,1]\n",
        "print ('LogLoss score: {}'.format(str(log_loss(y_test, test_preds_meta))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_test, test_preds_meta))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss score: 0.1699710727159766\n",
            "AUC score: 0.8054097221707287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACLMBUgualeM",
        "outputId": "9fb956ce-5c65-4320-b99b-1bde042c33f7"
      },
      "source": [
        "print ('LogLoss score: {}'.format(str(log_loss(y_test, np.mean(X_meta_test, axis=1)))))\n",
        "print ('AUC score: {}'.format(str(roc_auc_score(y_test, np.mean(X_meta_test, axis=1)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogLoss score: 0.165079201893919\n",
            "AUC score: 0.819913135514671\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}